version: "3"

vars:
  DATA_DIR: ./data
  ML_DIR: ./ml
  SCRIPTS_DIR: ./scripts
  PROCESSED_DIR: ./processed_data
  MODELS_DIR: ./models
  EVAL_DIR: ./evaluation
  DEVICE: "cuda" # Change to 'cpu' if no GPU available

tasks:
  install:
    desc: Install all dependencies
    cmds:
      - pip install -r ml/requirements.txt

  setup-dirs:
    desc: Create necessary directories if they don't exist
    cmds:
      - mkdir -p {{.PROCESSED_DIR}}/train
      - mkdir -p {{.PROCESSED_DIR}}/val
      - mkdir -p {{.PROCESSED_DIR}}/test
      - mkdir -p {{.MODELS_DIR}}
      - mkdir -p {{.EVAL_DIR}}
      - mkdir -p configs

  analyze-data:
    desc: Analyze the structure of .mat files in the data directory
    deps: [setup-dirs]
    cmds:
      - >
        python {{.SCRIPTS_DIR}}/process_mat_files.py
        --data_dir {{.DATA_DIR}}
        --output_dir {{.PROCESSED_DIR}}
        --analyze_only
        --sample_limit 100

  create-class-mapping:
    desc: Create a template for class name mapping
    deps: [analyze-data]
    cmds:
      - >
        python {{.SCRIPTS_DIR}}/process_mat_files.py
        --data_dir {{.DATA_DIR}}
        --output_dir {{.PROCESSED_DIR}}
        --create_class_mapping

  preprocess:
    desc: Preprocess the sign language data from .mat files
    deps: [setup-dirs]
    cmds:
      - >
        python {{.SCRIPTS_DIR}}/process_mat_files.py
        --data_dir {{.DATA_DIR}}
        --output_dir {{.PROCESSED_DIR}}
        --key_mapping '{"data":"features", "label":"target"}'
        --class_mapping {{.CLASS_MAPPING}}
    vars:
      CLASS_MAPPING: "{{.PROCESSED_DIR}}/class_mapping_template.csv"
    status:
      - test -f {{.PROCESSED_DIR}}/dataset_info.csv

  split-data:
    desc: Split the preprocessed data into train/val/test sets
    cmds:
      - >
        python {{.SCRIPTS_DIR}}/split_data.py
        --dataset_file {{.PROCESSED_DIR}}/dataset_info.csv
        --output_dir {{.PROCESSED_DIR}}
        --train_ratio 0.7
        --val_ratio 0.15
        --test_ratio 0.15
        --random_seed 42
    status:
      - test -f {{.PROCESSED_DIR}}/train_set.csv
      - test -f {{.PROCESSED_DIR}}/val_set.csv
      - test -f {{.PROCESSED_DIR}}/test_set.csv

  create-dev-subset:
    desc: Create a smaller development subset for quick iteration
    deps: [preprocess]
    cmds:
      - >
        python {{.SCRIPTS_DIR}}/split_data.py
        --dataset_file {{.PROCESSED_DIR}}/dataset_info.csv
        --output_dir {{.PROCESSED_DIR}}
        --create_subset
        --subset_size 1000
        --random_seed 42

  train:
    desc: Train the sign language recognition model
    deps: [split-data]
    cmds:
      - >
        python {{.ML_DIR}}/training/trainer.py
        --model cnn_lstm
        --train_csv {{.PROCESSED_DIR}}/train_set.csv
        --val_csv {{.PROCESSED_DIR}}/val_set.csv
        --data_dir {{.PROCESSED_DIR}}
        --output_dir {{.MODELS_DIR}}/cnn_lstm_$(date +%Y%m%d_%H%M%S)
        --config configs/training_config.json
    vars:
      CONFIG_FILE: ./configs/training_config.json
    status:
      - test -f {{.CONFIG_FILE}}

  train-handpose:
    desc: Train the sign language recognition model with hand pose features
    deps: [split-data]
    cmds:
      - >
        python {{.ML_DIR}}/training/trainer.py
        --model cnn_lstm_handpose
        --train_csv {{.PROCESSED_DIR}}/train_set.csv
        --val_csv {{.PROCESSED_DIR}}/val_set.csv
        --data_dir {{.PROCESSED_DIR}}
        --output_dir {{.MODELS_DIR}}/cnn_lstm_handpose_$(date +%Y%m%d_%H%M%S)
        --config configs/training_handpose_config.json
    vars:
      CONFIG_FILE: ./configs/training_handpose_config.json
    status:
      - test -f {{.CONFIG_FILE}}

  train-dev:
    desc: Train on the development subset for quick iteration
    deps: [create-dev-subset]
    cmds:
      - >
        python {{.ML_DIR}}/training/trainer.py
        --model cnn_lstm
        --train_csv {{.PROCESSED_DIR}}/development_subset.csv
        --val_csv {{.PROCESSED_DIR}}/development_subset.csv
        --data_dir {{.PROCESSED_DIR}}
        --output_dir {{.MODELS_DIR}}/dev_model_$(date +%Y%m%d_%H%M%S)
        --config configs/dev_training_config.json
    vars:
      CONFIG_FILE: ./configs/dev_training_config.json
    status:
      - test -f {{.CONFIG_FILE}}

  evaluate:
    desc: Evaluate a trained model
    cmds:
      - >
        python {{.ML_DIR}}/evaluation/evaluate.py
        --model {{.MODEL_TYPE}}
        --checkpoint {{.MODEL_PATH}}
        --test_csv {{.PROCESSED_DIR}}/test_set.csv
        --data_dir {{.PROCESSED_DIR}}
        --output_dir {{.EVAL_DIR}}/{{.MODEL_NAME}}_eval
        --config configs/eval_config.json
    vars:
      MODEL_TYPE: "cnn_lstm"
      MODEL_PATH: "{{.MODELS_DIR}}/latest/model_best.pth"
      MODEL_NAME: "latest"

  export:
    desc: Export the model to Core ML format
    cmds:
      - >
        python {{.ML_DIR}}/export_model.py
        --model_path {{.MODEL_PATH}}
        --framework {{.FRAMEWORK}}
        --output_path {{.OUTPUT_PATH}}
        --input_shape {{.INPUT_SHAPE}}
        --output_names {{.OUTPUT_NAMES}}
        --model_name {{.MODEL_NAME}}
    vars:
      MODEL_PATH: "{{.MODELS_DIR}}/latest/model_best.pth"
      FRAMEWORK: "pytorch"
      OUTPUT_PATH: "{{.MODELS_DIR}}/exported/SignLanguageTranslator.mlpackage"
      INPUT_SHAPE: "1,3,224,224"
      OUTPUT_NAMES: "output"
      MODEL_NAME: "SignLanguageTranslator"

  explore:
    desc: Run Jupyter notebook for data exploration
    cmds:
      - jupyter notebook {{.ML_DIR}}/notebooks/data_exploration.ipynb

  create-configs:
    desc: Create configuration files for training and evaluation
    deps: [setup-dirs]
    cmds:
      - |
        cat > configs/training_config.json << 'EOL'
        {
          "batch_size": 32,
          "num_epochs": 100,
          "learning_rate": 0.001,
          "weight_decay": 1e-4,
          "num_classes": 100,
          "use_landmarks": true,
          "early_stopping": 10,
          "max_seq_len": 60,
          "model_params": {
            "frame_dim": [3, 224, 224],
            "lstm_hidden_dim": 512,
            "lstm_layers": 2,
            "dropout": 0.5,
            "bidirectional": true,
            "attention": true
          }
        }
        EOL
      - |
        cat > configs/training_handpose_config.json << 'EOL'
        {
          "batch_size": 32,
          "num_epochs": 100,
          "learning_rate": 0.001,
          "weight_decay": 1e-4,
          "num_classes": 100,
          "use_landmarks": true,
          "early_stopping": 10,
          "max_seq_len": 60,
          "model_params": {
            "frame_dim": [3, 224, 224],
            "landmark_dim": 126,
            "lstm_hidden_dim": 512,
            "lstm_layers": 2,
            "dropout": 0.5,
            "bidirectional": true,
            "attention": true
          }
        }
        EOL
      - |
        cat > configs/dev_training_config.json << 'EOL'
        {
          "batch_size": 16,
          "num_epochs": 20,
          "learning_rate": 0.001,
          "weight_decay": 1e-4,
          "num_classes": 100,
          "use_landmarks": true,
          "early_stopping": 5,
          "max_seq_len": 60,
          "model_params": {
            "frame_dim": [3, 224, 224],
            "lstm_hidden_dim": 256,
            "lstm_layers": 1,
            "dropout": 0.3,
            "bidirectional": true,
            "attention": true
          }
        }
        EOL
      - |
        cat > configs/eval_config.json << 'EOL'
        {
          "batch_size": 32,
          "num_classes": 100,
          "use_landmarks": true,
          "max_seq_len": 60,
          "model_params": {
            "frame_dim": [3, 224, 224],
            "lstm_hidden_dim": 512,
            "lstm_layers": 2,
            "dropout": 0.5,
            "bidirectional": true,
            "attention": true
          }
        }
        EOL

  full-pipeline:
    desc: Run the full ML pipeline from preprocessing to evaluation
    cmds:
      - task: create-configs
      - task: analyze-data
      - task: create-class-mapping
      - task: preprocess
      - task: split-data
      - task: train
      - task: evaluate

  dev-pipeline:
    desc: Run a development pipeline for quick iteration
    cmds:
      - task: create-configs
      - task: preprocess
      - task: create-dev-subset
      - task: train-dev
      - task: evaluate MODEL_PATH={{.MODELS_DIR}}/dev_model_latest/model_best.pth MODEL_NAME=dev

  data-pipeline:
    desc: Run only the data preparation steps
    cmds:
      - task: create-configs
      - task: analyze-data
      - task: create-class-mapping
      - task: preprocess
      - task: split-data
